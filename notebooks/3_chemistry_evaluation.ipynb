{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c9f4ae",
   "metadata": {},
   "source": [
    "# Chemistry Evaluation Analysis\n",
    "\n",
    "This notebook processes and analyzes the results from a chemistry evaluation survey, which are stored in two separate CSV files: one for the **position model** and one for the **transition model**.\n",
    "\n",
    "The primary goal is to calculate performance metrics based on expert feedback for a series of questions (Q1-Q6).\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1.  **Position Model Evaluation**:\n",
    "    *   Loads the `position_model.csv` file, skipping the metadata header.\n",
    "    *   Cleans the data by removing empty rows and columns.\n",
    "    *   Separates feedback Q6 from other questions scores.\n",
    "    *   Calculates and displays summary statistics grouped by compound.\n",
    "\n",
    "2.  **Transition Model Evaluation**:\n",
    "    *   Loads the `transition_model.csv` file.\n",
    "    *   Performs manual data corrections.\n",
    "    *   Calculates and displays summary statistics for each question (Q1-Q6).\n",
    "    *   Analyzes the accuracy of reactant prediction by parsing the \"Correct reactants\" and \"Incorrect reactants\" columns to determine an overall accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "working_folder = os.path.abspath(os.path.join(current_directory, '..'))\n",
    "print(f\"Working Directory: {working_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings \n",
    "position_evaluation = working_folder + \"/results/chemistry_evaluation/250909_position_model.csv\"\n",
    "transition_evaluation = working_folder + \"/results/chemistry_evaluation/250909_transition_model.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file, skipping the first 5 rows using the skiprows parameter\n",
    "position = pd.read_csv(position_evaluation, skiprows=8)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b76242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all values are missing\n",
    "position.dropna(how='all', inplace=True)\n",
    "# Drop columns where all values are missing\n",
    "position.dropna(how='all', axis=1, inplace=True)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51560960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns in which Position == \"Q6\"\n",
    "\n",
    "position_q6_answers = position[position[\"Position\"] == \"Q6\"]\n",
    "position_q6_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38446fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_no_q6_answers = position[position[\"Position\"] != \"Q6\"]\n",
    "position_no_q6_answers['Q2'] = pd.to_numeric(position_no_q6_answers['Q2'])\n",
    "position_no_q6_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_question_scores(dataframe, question_column):\n",
    "    \"\"\"\n",
    "    Groups a DataFrame by 'Compound', calculates summary statistics, \n",
    "    and returns the summary along with key metrics.\n",
    "\n",
    "    Args:\n",
    "        dataframe: The input DataFrame.\n",
    "        question_column (str): The name of the question column to analyze.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - compound_summary (pd.DataFrame): The summary DataFrame per compound.\n",
    "        - correct (float): The total sum of scores across all compounds.\n",
    "        - all_rows (int): The total number of rows analyzed.\n",
    "        - overall_average (float): The overall average score.\n",
    "    \"\"\"\n",
    "    print(f\"--- Analysis for: {question_column} ---\")\n",
    "    \n",
    "    compound_summary = dataframe.groupby('Compound').agg(\n",
    "        sum_of_scores=(question_column, 'sum'),\n",
    "        num_rows=(question_column, 'size')\n",
    "    )\n",
    "\n",
    "    compound_summary['average_score'] = compound_summary['sum_of_scores'] / compound_summary['num_rows']\n",
    "    \n",
    "    correct = compound_summary[\"sum_of_scores\"].sum()\n",
    "    print(f\"Total Sum of Scores: {correct}\")\n",
    "    \n",
    "    all_rows = compound_summary[\"num_rows\"].sum()\n",
    "    print(f\"Total Number of Rows: {all_rows}\")\n",
    "    \n",
    "    overall_average = 0.0\n",
    "    if all_rows > 0:\n",
    "        overall_average = correct / all_rows\n",
    "        print(f\"Overall Average Score: {overall_average:.4f}\")\n",
    "    else:\n",
    "        print(\"Overall Average Score: N/A (no rows to calculate)\")\n",
    "    \n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    return compound_summary, correct, all_rows, overall_average\n",
    "\n",
    "compound_summary, correct, all_rows, overall_average = analyze_question_scores(position_no_q6_answers, \"Q1\")\n",
    "compound_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_summary, correct, all_rows, overall_average = analyze_question_scores(position_no_q6_answers, \"Q2\")\n",
    "compound_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d30a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_summary, correct, all_rows, overall_average = analyze_question_scores(position_no_q6_answers, \"Q3\")\n",
    "compound_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_summary, correct, all_rows, overall_average = analyze_question_scores(position_no_q6_answers, \"Q4\")\n",
    "compound_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ded29",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_summary, correct, all_rows, overall_average = analyze_question_scores(position_no_q6_answers, \"Q5\")\n",
    "compound_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d193e8",
   "metadata": {},
   "source": [
    "# Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d344c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file, skipping the first 5 rows using the skiprows parameter\n",
    "transition = pd.read_csv(transition_evaluation, skiprows=8)\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0432129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compound == LEi515, Position = 14 remove row because it is outside of the ontology.\n",
    "index_to_drop = transition[(transition['Compound'] == 'LEI515') & (transition['Position'] == 14)].index\n",
    "transition.drop(index_to_drop, inplace=True)\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb37186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lei401, position 3, remove from correct reactants \",5\" because the model sees as chemically invalid (even though its correct)\n",
    "condition = (transition['Compound'] == 'LEI401') & (transition['Position'] == 3)\n",
    "print(condition)\n",
    "# Get the current value, replace the substring, and set it back\n",
    "# This approach avoids potential SettingWithCopyWarning\n",
    "current_value = transition.loc[condition, 'Correct reactants'].iloc[0]\n",
    "print(current_value)\n",
    "new_value = current_value.replace(',5', '')\n",
    "print(new_value)\n",
    "transition.loc[condition, 'Correct reactants'] = new_value\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538412cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by compound get the sum of each question and number of rows per compound\n",
    "\n",
    "def prediction_evaluation(transition_df, row_name):\n",
    "    temp_transition = transition_df[transition_df[row_name] != \"-\"]\n",
    "    temp_transition[row_name] = pd.to_numeric(temp_transition[row_name])\n",
    "    compound_summary = temp_transition.groupby('Compound').agg(\n",
    "        # Sum all numeric columns\n",
    "        sum_of_scores=(row_name, 'sum'),  # Replace 'Score' with your actual score column name if different\n",
    "        # Count the number of rows for each compound\n",
    "        num_rows=(row_name, 'size')\n",
    "    )\n",
    "\n",
    "    compound_summary['average_score'] = compound_summary['sum_of_scores'] / compound_summary['num_rows']\n",
    "    correct = compound_summary[\"sum_of_scores\"].sum()\n",
    "    print(correct)\n",
    "    all = compound_summary[\"num_rows\"].sum()\n",
    "    print(all)\n",
    "    print(correct/all)\n",
    "    return compound_summary\n",
    "\n",
    "prediction_evaluation(transition, \"Q1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_evaluation(transition, \"Q2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860944fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_evaluation(transition, \"Q3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_evaluation(transition, \"Q4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_evaluation(transition, \"Q5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_evaluation(transition, \"Q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3e196",
   "metadata": {},
   "source": [
    "#### How often do we predict correct reactants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition[\"Correct reactants\"] = transition[\"Correct reactants\"].replace(\"-\", \"\")\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition[\"splitted_correct_reactants\"] = transition[\"Correct reactants\"].apply(lambda x: x.split(',') if x else [])\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition[\"Incorrect reactants\"] = transition[\"Incorrect reactants\"].fillna('')\n",
    "transition[\"splitted_incorrect_reactants\"] = transition[\"Incorrect reactants\"].apply(lambda x: x.split(',') if x else [])\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea304e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition[\"splitted_correct_reactants_len\"] = transition[\"splitted_correct_reactants\"].apply(lambda x: len(x))\n",
    "transition[\"splitted_incorrect_reactants_len\"] = transition[\"splitted_incorrect_reactants\"].apply(lambda x: len(x))\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition[\"splitted_correct_reactants_len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaba25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition[\"splitted_incorrect_reactants_len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04912c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_analysis = transition.groupby('Compound').agg(\n",
    "    total_correct_reactants=('splitted_correct_reactants_len', 'sum'),\n",
    "    total_incorrect_reactants=('splitted_incorrect_reactants_len', 'sum')\n",
    ")\n",
    "compound_analysis[\"total_reactants\"] = compound_analysis[\"total_correct_reactants\"] + compound_analysis[\"total_incorrect_reactants\"]\n",
    "compound_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = compound_analysis[\"total_correct_reactants\"].sum()\n",
    "print(correct)\n",
    "total = compound_analysis[\"total_reactants\"].sum()\n",
    "print(total)\n",
    "accuracy = correct / total\n",
    "accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retro_llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
